{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db28471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshnevin/.pyenv/versions/3.7.12/envs/rlenv37/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n",
      "/Users/joshnevin/.pyenv/versions/3.7.12/envs/rlenv37/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib\n",
    "#import config InlineBackend.figure_format = 'svg'\n",
    "import tensorflow as tf\n",
    "\n",
    "# silencing tensorflow warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "from datetime import datetime\n",
    "\n",
    "tf.__version__ # printint out tensorflow version used\n",
    "import stable_baselines\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "#stable_baselines.__version__ # printing out stable_baselines version used\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0fa0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/joshnevin/RL_FOCSLab/topologies/nsfnet_chen_5-paths_directional.h5', 'rb') as f:\n",
    "    topology = pickle.load(f)\n",
    "# node probabilities from https://github.com/xiaoliangchenUCD/DeepRMSA/blob/6708e9a023df1ec05bfdc77804b6829e33cacfe4/Deep_RMSA_A3C.py#L77\n",
    "node_request_probabilities = np.array([0.01801802, 0.04004004, 0.05305305, 0.01901902, 0.04504505,\n",
    "       0.02402402, 0.06706707, 0.08908909, 0.13813814, 0.12212212,\n",
    "       0.07607608, 0.12012012, 0.01901902, 0.16916917])\n",
    "load = int(1e10)\n",
    "env_args = dict(topology=topology, seed=1, load = load,\n",
    "                allow_rejection=False, # the agent cannot proactively reject a request\n",
    "                mean_service_holding_time=1e6, # value is not set as in the paper to achieve comparable reward values\n",
    "                episode_length=1000, node_request_probabilities=node_request_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c26e4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('RWAFOCS-v2', **env_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0211dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO2.load('/Users/joshnevin/RL_FOCSLab/tmp/RWAFOCS-ppo/2021-12-30_4/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45c4b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1,deterministic =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d81796e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb4d7e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acd3d410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole training process statistics:\n",
      "Path action probability: [0.54992076 0.4437401  0.00475436 0.00158479 0.        ]\n",
      "Wavelength action probability: [0.0110935  0.00158479 0.0110935  0.00792393 0.00950872 0.0110935\n",
      " 0.00158479 0.00475436 0.00950872 0.01426307 0.00475436 0.00475436\n",
      " 0.0110935  0.00633914 0.00158479 0.00792393 0.00950872 0.02377179\n",
      " 0.0110935  0.00633914 0.00633914 0.00950872 0.00633914 0.00792393\n",
      " 0.00792393 0.01267829 0.00950872 0.01584786 0.00950872 0.00792393\n",
      " 0.01426307 0.00633914 0.00792393 0.00633914 0.01267829 0.00633914\n",
      " 0.01426307 0.00792393 0.01584786 0.01901743 0.00633914 0.022187\n",
      " 0.0110935  0.01901743 0.01267829 0.01426307 0.01426307 0.01267829\n",
      " 0.00475436 0.00633914 0.00475436 0.00633914 0.0110935  0.01426307\n",
      " 0.01267829 0.0110935  0.00792393 0.00950872 0.00950872 0.00950872\n",
      " 0.02377179 0.00633914 0.01584786 0.00792393 0.00475436 0.00475436\n",
      " 0.00633914 0.00950872 0.03169572 0.022187   0.00633914 0.01267829\n",
      " 0.00950872 0.00316957 0.00475436 0.00950872 0.022187   0.0110935\n",
      " 0.00950872 0.00950872 0.00792393 0.00633914 0.00475436 0.0110935\n",
      " 0.01267829 0.01743265 0.00158479 0.00633914 0.00792393 0.00950872\n",
      " 0.00158479 0.00633914 0.00158479 0.00633914 0.0110935  0.01426307\n",
      " 0.01267829 0.01426307 0.01426307 0.00633914]\n",
      "Load (Erlangs): 10000000000\n",
      "Service bit rate (Gb/s): 25.0\n",
      "Total number of services: 1000\n",
      "Total number of accepted services: 631\n",
      "Blocking probability: 0.369\n",
      "Number of services on existing lightpaths: 35\n",
      "Number of services released: 0\n",
      "Number of transmitters on each node: [ 10.  26.  32.  19.  28.   9.  45.  60.  69.  73.  47.  67.  11. 100.]\n",
      "Number of receivers on each node: [13. 31. 30.  8. 28. 19. 39. 60. 76. 89. 39. 61.  8. 95.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Whole training process statistics:\")\n",
    "rnd_path_action_probability = np.sum(env.actions_output, axis=1) / np.sum(env.actions_output)\n",
    "rnd_wavelength_action_probability = np.sum(env.actions_output, axis=0) / np.sum(env.actions_output)\n",
    "print('Path action probability:', np.sum(env.actions_output, axis=1) / np.sum(env.actions_output))\n",
    "print('Wavelength action probability:', np.sum(env.actions_output, axis=0) / np.sum(env.actions_output))\n",
    "num_lps_reused = env.num_lightpaths_reused\n",
    "print('Load (Erlangs):', load)\n",
    "print('Service bit rate (Gb/s):', env.service.bit_rate/1e9)\n",
    "print('Total number of services:', env.services_processed)\n",
    "print('Total number of accepted services:', env.services_accepted)\n",
    "print('Blocking probability:', 1 - env.services_accepted/env.services_processed)\n",
    "print('Number of services on existing lightpaths:', num_lps_reused)\n",
    "print('Number of services released:', env.num_lightpaths_released)\n",
    "print('Number of transmitters on each node:', env.num_transmitters)\n",
    "print('Number of receivers on each node:', env.num_receivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5170ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and visualize\n",
    "obs = env.reset()\n",
    "done = False\n",
    "total_reward = []\n",
    "while not done:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    total_reward.append(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "202b54cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f148da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
